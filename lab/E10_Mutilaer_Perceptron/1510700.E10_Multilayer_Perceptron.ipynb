{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sid = '1510700'\n",
    "name = 'Nguyen Thanh Dat'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn.model_selection as sk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài 1\n",
    "Trong ví dụ ở trên, chúng ta đã sử dụng toàn bộ tập dữ liệu để train, và đồng thời cũng lấy chính dữ liệu đó để test, điều đó\n",
    "dẫn tới trường hợp \"học khớp\" (overfitting).\n",
    "Sinh viên hãy chia tập dữ liệu ra làm 2 phần riêng biệt ~90% để train và ~10% còn lại dùng để test. (sửa trực tiếp ở code ví\n",
    "dụ ở trên)\n",
    "Hãy cho biết kích thước của mỗi tập sau khi tách ra\n",
    "Hãy cho biết các nhận xét của kết quả khi chia ra 2 tập rời như vậy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 cost=312.579218864\n",
      "Epoch: 0002 cost=95.374959994\n",
      "Epoch: 0003 cost=70.981094340\n",
      "Epoch: 0004 cost=56.736979911\n",
      "Epoch: 0005 cost=47.729590488\n",
      "Epoch: 0006 cost=42.816328885\n",
      "Epoch: 0007 cost=37.214596614\n",
      "Epoch: 0008 cost=34.447859274\n",
      "Epoch: 0009 cost=31.783540420\n",
      "Epoch: 0010 cost=29.109287397\n",
      "Epoch: 0011 cost=27.610781347\n",
      "Epoch: 0012 cost=26.021569273\n",
      "Epoch: 0013 cost=24.704048311\n",
      "Epoch: 0014 cost=22.992715377\n",
      "Epoch: 0015 cost=21.620997228\n",
      "Epoch: 0016 cost=21.313882766\n",
      "Epoch: 0017 cost=20.156914326\n",
      "Epoch: 0018 cost=19.255096169\n",
      "Epoch: 0019 cost=19.066982886\n",
      "Epoch: 0020 cost=18.191530964\n",
      "Epoch: 0021 cost=17.139487472\n",
      "Epoch: 0022 cost=16.885087367\n",
      "Epoch: 0023 cost=16.404754116\n",
      "Epoch: 0024 cost=15.783774483\n",
      "Epoch: 0025 cost=15.497318083\n",
      "Epoch: 0026 cost=15.584400601\n",
      "Epoch: 0027 cost=15.234909901\n",
      "Epoch: 0028 cost=14.424782609\n",
      "Epoch: 0029 cost=14.233547849\n",
      "Epoch: 0030 cost=13.958949972\n",
      "Optimization Finished!\n",
      "Accuracy: 0.876\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# load dataset\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 30\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "# Create model\n",
    "def multilayer_perceptron(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Construct model\n",
    "logits = multilayer_perceptron(X)\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([train_op, loss_op], feed_dict={X: batch_x,\n",
    "            Y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "            # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "    # Test model\n",
    "    pred = tf.nn.softmax(logits) # Apply softmax to logits\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train 55000\n",
      "size of test 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"size of train\",len(mnist.train.images))\n",
    "\n",
    "print(\"size of test\",len(mnist.test.images))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "Trong tập dữ liệu trên đã chia ra 2 tập train và test có tỉ lệ 5,5:1. Sau khi test thì kết qủa là Accuracy ~ 0.876 tương đối tốt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài 2\n",
    "Hãy sử dụng tập dữ liệu cifar 10 (https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "Hãy xử lý dữ liệu, thay đổi model (nếu cần) và điều chỉnh các thông số cần thiết phù hợp với dữ liệu này.\n",
    "Sinh viên hãy train, test và cho biết kết quả đạt được (yêu cầu giữ kết quả output khi chạy train, test lúc nộp bài ở các cell tiếp theo ở dưới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cifar10'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c2434283a9e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import  data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cifar10'"
     ]
    }
   ],
   "source": [
    "# Import  data\n",
    "import cifar10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
